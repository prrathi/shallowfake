{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pystoi import stoi\n",
    "from loss import *\n",
    "from scipy.io import wavfile\n",
    "import whisper\n",
    "from whisper.audio import log_mel_spectrogram\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filepaths, constants\n",
    "data_dir = '/home/thegoods/'\n",
    "text_path = '/home/thegoods/clean/labels.csv'\n",
    "WHISPER_PGD = 'whisper_pgd_200'\n",
    "WHISPER_GAN = 'whisper_gan'\n",
    "DF_AUDIO = 'DF_audio'\n",
    "DF_TEXT = 'DF_text'\n",
    "def getPath(mode,attack,id,split='test'):\n",
    "    if mode==\"clean\":\n",
    "        return os.path.join(data_dir,mode,split,f'{id}.wav')\n",
    "    elif mode=='gen':\n",
    "        return os.path.join(data_dir,mode,attack,split,f'{id}.npy')\n",
    "    else:\n",
    "        return os.path.join(data_dir,mode,attack,split,f'{id}.wav')\n",
    "inputs = [WHISPER_PGD]\n",
    "N_SAMPLES = 100\n",
    "# inputs = [WHISPER_PGD, WHISPER_GAN, DF_AUDIO, DF_TEXT]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = {}\n",
    "for l in open(text_path,\"r\").readlines():\n",
    "    parts = l.split(',')\n",
    "    texts[parts[0]] = parts[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEEPFAKE GENERATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append('./encoder/')\n",
    "from encoder import inference as encoder\n",
    "from vocoder import inference as vocoder\n",
    "from synthesizer.inference import Synthesizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded encoder \"encoder.pt\" trained to step 1564501\n",
      "Synthesizer using device: cuda\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at saved_models/default/vocoder.pt\n"
     ]
    }
   ],
   "source": [
    "encoder.load_model(Path(\"saved_models/default/encoder.pt\"))\n",
    "synthesizer = Synthesizer(Path('saved_models/default/synthesizer.pt'))\n",
    "vocoder.load_model(Path('saved_models/default/vocoder.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AudioSynthesisRun(preprocessed_wav_torch,text):       \n",
    "    embed = encoder.embed_utterance(preprocessed_wav_torch,using_partials=False)\n",
    "    texts = [text]\n",
    "    embeds = [embed]\n",
    "\n",
    "    specs = synthesizer.synthesize_spectrograms(texts, embeds)\n",
    "    spec = specs[0]\n",
    "    return spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genDFs(id):\n",
    "    c_text = texts[id]\n",
    "    for inp in inputs:\n",
    "        noise_fname = getPath('noise',inp,id)\n",
    "        sample_rate, noise_samples = wavfile.read(noise_fname)\n",
    "        noise_orig = np.float32(noise_samples)\n",
    "        gen_fname = getPath('gen',inp,id)\n",
    "        print(gen_fname)\n",
    "        np.save(gen_fname, AudioSynthesisRun(torch.from_numpy(noise_orig), c_text).detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/thegoods/gen/whisper_pgd_200/test/61-70968-0032.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 429])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable Parameters: 30.870M\n",
      "Loaded synthesizer \"synthesizer.pt\" trained to step 295000\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/4446-2271-0023.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 227])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/237-134500-0037.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 711])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/1284-1180-0023.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 562])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/2300-131720-0038.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 562])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/4507-16021-0007.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 264])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/5142-33396-0009.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 338])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/4077-13754-0014.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 1098])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/6930-76324-0023.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 486])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/672-122797-0018.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 494])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/260-123288-0002.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 726])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/1320-122617-0003.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 629])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/7127-75947-0030.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 277])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/4446-2275-0028.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 358])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/2961-960-0015.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 784])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/7021-85628-0022.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 515])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/4992-41797-0014.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 722])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/2094-142345-0056.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 385])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/7729-102255-0029.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 707])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/4992-41797-0022.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 646])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/7176-88083-0019.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 582])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/2094-142345-0060.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 272])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/1995-1826-0011.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 895])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/237-134493-0003.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 1277])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/2830-3980-0000.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 374])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/1284-1180-0007.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 627])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/6829-68769-0046.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 258])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/1284-134647-0004.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 1284])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/5639-40744-0023.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 1393])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/4446-2271-0001.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 636])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/2094-142345-0020.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 244])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/1188-133604-0039.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 663])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/6829-68771-0031.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 252])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/4970-29095-0005.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 466])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/5142-33396-0017.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 264])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/672-122797-0003.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 477])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/4446-2275-0018.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 232])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/260-123286-0014.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 299])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/7176-88083-0003.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 761])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/908-31957-0012.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 762])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/1089-134686-0011.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 1245])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/6930-76324-0015.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 1241])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/61-70968-0057.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 507])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/1284-1180-0009.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 629])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/7729-102255-0013.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 268])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/7021-79740-0000.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 1113])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/61-70968-0010.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 830])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/908-31957-0009.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 771])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/6829-68771-0006.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 593])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/6930-81414-0019.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 339])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/121-127105-0023.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 1092])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/5683-32866-0005.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 460])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/4446-2275-0020.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 273])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/237-126133-0016.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 426])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/1580-141083-0049.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 385])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/1284-1181-0013.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 1267])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/2961-961-0003.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 474])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/237-134500-0019.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 287])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/1320-122617-0000.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 784])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/2830-3980-0022.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 328])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/8463-294828-0008.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 266])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/6829-68769-0042.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 218])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/5639-40744-0013.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 687])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/61-70968-0048.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 303])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/121-127105-0002.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 750])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/908-157963-0021.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 1025])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/5105-28240-0008.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 1149])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/1320-122612-0013.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 656])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/2830-3980-0070.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 374])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/7021-85628-0023.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 904])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/2830-3980-0066.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 609])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/61-70970-0007.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 449])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/8555-284447-0013.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 905])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/1580-141083-0022.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 330])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/7021-85628-0013.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 1214])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/672-122797-0040.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 513])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/2961-961-0020.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 613])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/2830-3979-0009.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 836])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/4970-29093-0001.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 1193])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/237-134500-0025.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 164])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/8555-284447-0011.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 196])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/8230-279154-0027.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 1114])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/4446-2275-0022.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 329])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/5142-33396-0003.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 348])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/4446-2273-0011.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 280])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/1221-135766-0003.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 1373])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/4446-2271-0010.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 314])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/4970-29095-0026.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 1094])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/8455-210777-0062.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 306])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/4507-16021-0053.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 810])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/6930-75918-0000.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 351])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/6930-76324-0001.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 321])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/237-134500-0042.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 258])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/2961-961-0007.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 851])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/4446-2275-0012.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 603])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/4507-16021-0046.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 460])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/5105-28240-0019.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 625])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/1580-141083-0048.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 279])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/8555-284449-0001.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 864])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/61-70970-0035.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 741])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n",
      "/home/thegoods/gen/whisper_pgd_200/test/1995-1837-0008.npy\n",
      "nmels 40\n",
      "Before transpose shape torch.Size([40, 196])\n",
      "\n",
      "| Generating 1/1\n",
      "\n",
      "\n",
      "Done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    i = 0\n",
    "    for fname in os.listdir(os.path.join(data_dir,'clean','test')):\n",
    "        id = fname.strip('.wav')\n",
    "        genDFs(id)\n",
    "        i += 1\n",
    "        if i > N_SAMPLES:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "del vocoder\n",
    "del encoder\n",
    "del synthesizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STOI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def STOI(orig,noised,sample_rate):\n",
    "    return stoi(orig,noised,sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Prob Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = whisper.load_model(\"base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getProb(mel_spec, real_text, model=model):\n",
    "    return get_loss_single_segment(model, spec=mel_spec, label=real_text).to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WhisperComparison(g_spec, clean_text, clean_norm):\n",
    "    return getProb(g_spec, clean_text) - clean_norm\n",
    "# TODO - subtract or divide?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spec Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tslearn/bases/bases.py:15: UserWarning: h5py not installed, hdf5 features will not be supported.\n",
      "Install h5py to use hdf5 features: http://docs.h5py.org/\n",
      "  warn(h5py_msg)\n"
     ]
    }
   ],
   "source": [
    "from tslearn.metrics import dtw, dtw_path\n",
    "l1loss = nn.L1Loss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use scipy sparse maybe to save space\n",
    "def getAlignmentMatrices(path):\n",
    "    M = len(path)\n",
    "    l1m = max(path, key=lambda x: x[0])[0]\n",
    "    l2m = max(path, key=lambda x: x[1])[1]\n",
    "\n",
    "    A1 = np.zeros((M,l1m+1),dtype=np.float32)\n",
    "    A2 = np.zeros((M,l2m+1),dtype=np.float32)\n",
    "\n",
    "\n",
    "    for i in range(len(path)):\n",
    "        p1,p2 = path[i]\n",
    "        A1[i,p1] = 1.0\n",
    "        A2[i,p2] = 1.0\n",
    "\n",
    "    return torch.from_numpy(A1).detach(),torch.from_numpy(A2).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l1Entropy(orig_spec, noised_spec):\n",
    "    return l1loss(noised_spec,orig_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_objective_entropy(synth_speech_spec, target_speech_spec):\n",
    "    np1 = (synth_speech_spec - synth_speech_spec.mean())/synth_speech_spec.std()\n",
    "    np2 = (target_speech_spec - target_speech_spec.mean())/target_speech_spec.std()\n",
    "\n",
    "    pathCalc1 = np1.clone().detach().numpy()\n",
    "    pathCalc2 = np2.clone().detach().numpy()\n",
    "\n",
    "    optimal_path, dtw_score = dtw_path(pathCalc1, pathCalc2, global_constraint=\"sakoe_chiba\", sakoe_chiba_radius=5)\n",
    "    A1,A2 = getAlignmentMatrices(optimal_path)\n",
    "\n",
    "    stretched1 = torch.matmul(A1,np1)\n",
    "    stretched2 = torch.matmul(A2,np2)\n",
    "\n",
    "    return l1Entropy(stretched1,stretched2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shrinkSpec(spec):\n",
    "    return spec\n",
    "    wav_init_spec = torch.log(torch.clamp(spec, min=1e-10, max=1e5))\n",
    "\n",
    "    np1_scale = wav_init_spec.clone().detach().numpy()\n",
    "    np1_scale = (np1_scale - np1_scale.min())/np1_scale.std()\n",
    "    mask = np.linalg.norm(np1_scale, axis=1) <= 17.5\n",
    "\n",
    "    wav_init_spec = torch.tensor(wav_init_spec[~mask, :],requires_grad=True)\n",
    "    return wav_init_spec\n",
    "    # implement shrinking code - TODO?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compareSpecs(clean_spec, gen_spec):\n",
    "    # print('clean_spec.shape',clean_spec.shape)\n",
    "    # print('gen_spec.shape',gen_spec.shape)\n",
    "    return compute_objective_entropy(gen_spec, clean_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Put it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMetrics(id):\n",
    "    output = {inp : {} for inp in inputs}\n",
    "    # get clean spectrogram\n",
    "    clean_fname = getPath('clean','',id)\n",
    "    sample_rate, clean_samples = wavfile.read(clean_fname)\n",
    "    clean_orig = np.float32(clean_samples)\n",
    "    clean_spec = log_mel_spectrogram(clean_orig) # what sampling rate is used?\n",
    "    clean_spec_small = shrinkSpec(clean_spec.T).T\n",
    "    # print('clean_spec_small.shape',clean_spec_small.shape)\n",
    "\n",
    "    try:\n",
    "        clean_text = texts[id]\n",
    "    except KeyError:\n",
    "        return None\n",
    "    whisper_baseline = getProb(clean_spec.to(model.device), clean_text)\n",
    "    del clean_spec\n",
    "\n",
    "    for inp in inputs:\n",
    "        # get noised waveform, and get stoi results\n",
    "        noise_path = getPath('noise',inp,id)\n",
    "        inp_sr, inp_samples = wavfile.read(noise_path)\n",
    "        assert inp_samples.shape == clean_samples.shape\n",
    "        inp_orig = np.float32(inp_samples)\n",
    "        stoi_res = STOI(clean_orig, inp_orig, inp_sr)\n",
    "        output[inp]['stoi'] = stoi_res\n",
    "        \n",
    "        # get generated spectrogram, run our metrics on it\n",
    "        gen_path = getPath('gen',inp,id)\n",
    "        gen_spec = torch.from_numpy(np.load(gen_path))\n",
    "        gen_spec_small = shrinkSpec(gen_spec.T).T\n",
    "        # print('gen_spec_small.shape',gen_spec_small.shape)\n",
    "\n",
    "\n",
    "        # transpose for compareSpecs, because whisper has the dimensions flipped\n",
    "        output[inp]['waveformCompare'] = compareSpecs(clean_spec_small.T, gen_spec_small.T).item()\n",
    "        output[inp]['textCompare'] = WhisperComparison(gen_spec,clean_text,whisper_baseline).item()\n",
    "    return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61-70968-0032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amank/mlsp-speech-noiser-2/loss.py:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_tokens: Tensor = torch.tensor(label).repeat(\n",
      "/home/amank/mlsp-speech-noiser-2/loss.py:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_tokens: Tensor = torch.tensor(label).repeat(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4446-2271-0023\n",
      "237-134500-0037\n",
      "1284-1180-0023\n",
      "2300-131720-0038\n",
      "4507-16021-0007\n",
      "5142-33396-0009\n",
      "4077-13754-0014\n",
      "6930-76324-0023\n",
      "672-122797-0018\n",
      "260-123288-0002\n",
      "1320-122617-0003\n",
      "7127-75947-0030\n",
      "4446-2275-0028\n",
      "2961-960-0015\n",
      "7021-85628-0022\n",
      "4992-41797-0014\n",
      "2094-142345-0056\n",
      "7729-102255-0029\n",
      "4992-41797-0022\n",
      "7176-88083-0019\n",
      "2094-142345-0060\n",
      "1995-1826-0011\n",
      "237-134493-0003\n",
      "2830-3980-0000\n",
      "1284-1180-0007\n",
      "6829-68769-0046\n",
      "1284-134647-0004\n",
      "5639-40744-0023\n",
      "4446-2271-0001\n",
      "2094-142345-0020\n",
      "1188-133604-0039\n",
      "6829-68771-0031\n",
      "4970-29095-0005\n",
      "5142-33396-0017\n",
      "672-122797-0003\n",
      "4446-2275-0018\n",
      "260-123286-0014\n",
      "7176-88083-0003\n",
      "908-31957-0012\n",
      "1089-134686-0011\n",
      "6930-76324-0015\n",
      "61-70968-0057\n",
      "1284-1180-0009\n",
      "7729-102255-0013\n",
      "7021-79740-0000\n",
      "61-70968-0010\n",
      "908-31957-0009\n",
      "6829-68771-0006\n",
      "6930-81414-0019\n",
      "121-127105-0023\n",
      "5683-32866-0005\n",
      "4446-2275-0020\n",
      "237-126133-0016\n",
      "1580-141083-0049\n",
      "1284-1181-0013\n",
      "2961-961-0003\n",
      "237-134500-0019\n",
      "1320-122617-0000\n",
      "2830-3980-0022\n",
      "8463-294828-0008\n",
      "6829-68769-0042\n",
      "5639-40744-0013\n",
      "61-70968-0048\n",
      "121-127105-0002\n",
      "908-157963-0021\n",
      "5105-28240-0008\n",
      "1320-122612-0013\n",
      "2830-3980-0070\n",
      "7021-85628-0023\n",
      "2830-3980-0066\n",
      "61-70970-0007\n",
      "8555-284447-0013\n",
      "1580-141083-0022\n",
      "7021-85628-0013\n",
      "672-122797-0040\n",
      "2961-961-0020\n",
      "2830-3979-0009\n",
      "4970-29093-0001\n",
      "237-134500-0025\n",
      "8555-284447-0011\n",
      "8230-279154-0027\n",
      "4446-2275-0022\n",
      "5142-33396-0003\n",
      "4446-2273-0011\n",
      "1221-135766-0003\n",
      "4446-2271-0010\n",
      "4970-29095-0026\n",
      "8455-210777-0062\n",
      "4507-16021-0053\n",
      "6930-75918-0000\n",
      "6930-76324-0001\n",
      "237-134500-0042\n",
      "2961-961-0007\n",
      "4446-2275-0012\n",
      "4507-16021-0046\n",
      "5105-28240-0019\n",
      "1580-141083-0048\n",
      "8555-284449-0001\n",
      "61-70970-0035\n",
      "1995-1837-0008\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    all_res = {}\n",
    "    i = 0\n",
    "    for fname in os.listdir(os.path.join(data_dir,'clean','test')):\n",
    "        id = fname.strip('.wav')\n",
    "        print(id)\n",
    "        res = getMetrics(id)\n",
    "        all_res[id] = res\n",
    "        torch.cuda.empty_cache()\n",
    "        i += 1\n",
    "        if i > N_SAMPLES:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'61-70968-0032': {'whisper_pgd_200': {'stoi': 0.9994623530279937, 'waveformCompare': 0.782703161239624, 'textCompare': 3.170424222946167}}, '4446-2271-0023': {'whisper_pgd_200': {'stoi': 0.9989117188309299, 'waveformCompare': 0.524455726146698, 'textCompare': 1.939270257949829}}, '237-134500-0037': {'whisper_pgd_200': {'stoi': 0.9996103978563073, 'waveformCompare': 0.6536287069320679, 'textCompare': 0.9174906015396118}}, '1284-1180-0023': {'whisper_pgd_200': {'stoi': 0.9993792735518832, 'waveformCompare': 0.677111029624939, 'textCompare': 0.7021005153656006}}, '2300-131720-0038': {'whisper_pgd_200': {'stoi': 0.9990672877034045, 'waveformCompare': 0.5104990601539612, 'textCompare': 1.3016111850738525}}, '4507-16021-0007': {'whisper_pgd_200': {'stoi': 0.9993173818279284, 'waveformCompare': 0.5504000782966614, 'textCompare': 0.6158318519592285}}, '5142-33396-0009': {'whisper_pgd_200': {'stoi': 0.9997090144048754, 'waveformCompare': 0.6325445175170898, 'textCompare': 0.8855679035186768}}, '4077-13754-0014': {'whisper_pgd_200': {'stoi': 0.9997545261176708, 'waveformCompare': 0.6398367285728455, 'textCompare': 1.9387857913970947}}, '6930-76324-0023': {'whisper_pgd_200': {'stoi': 0.9994591665716891, 'waveformCompare': 0.5854828953742981, 'textCompare': -0.03777766227722168}}, '672-122797-0018': {'whisper_pgd_200': {'stoi': 0.9983407840433295, 'waveformCompare': 0.6780080199241638, 'textCompare': 0.8244218826293945}}, '260-123288-0002': {'whisper_pgd_200': {'stoi': 0.9993546457223567, 'waveformCompare': 0.6001924872398376, 'textCompare': 0.055867552757263184}}, '1320-122617-0003': {'whisper_pgd_200': {'stoi': 0.9995187187077635, 'waveformCompare': 0.5768842697143555, 'textCompare': 0.0899648666381836}}, '7127-75947-0030': {'whisper_pgd_200': {'stoi': 0.9998062382299857, 'waveformCompare': 0.5072800517082214, 'textCompare': 1.5823900699615479}}, '4446-2275-0028': {'whisper_pgd_200': {'stoi': 0.9997816555485916, 'waveformCompare': 0.5842698812484741, 'textCompare': 1.309781551361084}}, '2961-960-0015': {'whisper_pgd_200': {'stoi': 0.9990956128424651, 'waveformCompare': 0.5586481690406799, 'textCompare': 1.9094890356063843}}, '7021-85628-0022': {'whisper_pgd_200': {'stoi': 0.9993389673659043, 'waveformCompare': 0.6057165265083313, 'textCompare': 1.4659428596496582}}, '4992-41797-0014': {'whisper_pgd_200': {'stoi': 0.9994696032120475, 'waveformCompare': 0.6500583291053772, 'textCompare': 0.5285470485687256}}, '2094-142345-0056': {'whisper_pgd_200': {'stoi': 0.9968634390018167, 'waveformCompare': 0.7142810821533203, 'textCompare': -0.03492629528045654}}, '7729-102255-0029': {'whisper_pgd_200': {'stoi': 0.9986574220540029, 'waveformCompare': 0.6320878863334656, 'textCompare': 0.1764901876449585}}, '4992-41797-0022': {'whisper_pgd_200': {'stoi': 0.9993891961111082, 'waveformCompare': 0.7399352192878723, 'textCompare': 0.8348026275634766}}, '7176-88083-0019': {'whisper_pgd_200': {'stoi': 0.9992090170026316, 'waveformCompare': 0.6998971700668335, 'textCompare': 0.5041829347610474}}, '2094-142345-0060': {'whisper_pgd_200': {'stoi': 0.9980025791771053, 'waveformCompare': 0.609579861164093, 'textCompare': 0.6529958248138428}}, '1995-1826-0011': {'whisper_pgd_200': {'stoi': 0.9991590698238373, 'waveformCompare': 0.5611312985420227, 'textCompare': 0.39554524421691895}}, '237-134493-0003': {'whisper_pgd_200': {'stoi': 0.9996809295842121, 'waveformCompare': 0.669045627117157, 'textCompare': 1.2762619256973267}}, '2830-3980-0000': {'whisper_pgd_200': {'stoi': 0.9989551160961861, 'waveformCompare': 0.598905086517334, 'textCompare': 2.57269287109375}}, '1284-1180-0007': {'whisper_pgd_200': {'stoi': 0.9994664074616619, 'waveformCompare': 0.5847787857055664, 'textCompare': 1.2667251825332642}}, '6829-68769-0046': {'whisper_pgd_200': {'stoi': 0.999673287047163, 'waveformCompare': 0.5187946557998657, 'textCompare': 0.9244198799133301}}, '1284-134647-0004': {'whisper_pgd_200': {'stoi': 0.9985041869313189, 'waveformCompare': 0.6017512083053589, 'textCompare': 0.6322016716003418}}, '5639-40744-0023': {'whisper_pgd_200': {'stoi': 0.9994449497241109, 'waveformCompare': 0.5195042490959167, 'textCompare': 0.29925888776779175}}, '4446-2271-0001': {'whisper_pgd_200': {'stoi': 0.9983990691591688, 'waveformCompare': 0.6265513300895691, 'textCompare': 0.3134702444076538}}, '2094-142345-0020': {'whisper_pgd_200': {'stoi': 0.9983177928284878, 'waveformCompare': 0.7616897225379944, 'textCompare': 1.3216090202331543}}, '1188-133604-0039': {'whisper_pgd_200': {'stoi': 0.9971170383998855, 'waveformCompare': 0.7008579969406128, 'textCompare': 1.1829440593719482}}, '6829-68771-0031': {'whisper_pgd_200': {'stoi': 0.9997310458937431, 'waveformCompare': 0.5128414630889893, 'textCompare': 1.165543556213379}}, '4970-29095-0005': {'whisper_pgd_200': {'stoi': 0.9995029910571099, 'waveformCompare': 0.6562078595161438, 'textCompare': 2.024343252182007}}, '5142-33396-0017': {'whisper_pgd_200': {'stoi': 0.999761001442347, 'waveformCompare': 0.5779665112495422, 'textCompare': 0.8471715450286865}}, '672-122797-0003': {'whisper_pgd_200': {'stoi': 0.9983919436449661, 'waveformCompare': 0.6206285357475281, 'textCompare': 1.04988694190979}}, '4446-2275-0018': {'whisper_pgd_200': {'stoi': 0.9998070941143927, 'waveformCompare': 0.6532735824584961, 'textCompare': 0.9444210529327393}}, '260-123286-0014': {'whisper_pgd_200': {'stoi': 0.9995081104843738, 'waveformCompare': 0.5565056204795837, 'textCompare': 0.9227921962738037}}, '7176-88083-0003': {'whisper_pgd_200': {'stoi': 0.9992351976359918, 'waveformCompare': 0.6985557079315186, 'textCompare': 0.9357926845550537}}, '908-31957-0012': {'whisper_pgd_200': {'stoi': 0.998602776906759, 'waveformCompare': 0.544020414352417, 'textCompare': 1.0936872959136963}}, '1089-134686-0011': {'whisper_pgd_200': {'stoi': 0.9995619912607445, 'waveformCompare': 0.5461953282356262, 'textCompare': 0.2642796039581299}}, '6930-76324-0015': {'whisper_pgd_200': {'stoi': 0.999162864183506, 'waveformCompare': 0.7586562037467957, 'textCompare': 1.7423672676086426}}, '61-70968-0057': {'whisper_pgd_200': {'stoi': 0.9991960180321492, 'waveformCompare': 0.5934033393859863, 'textCompare': 0.20229792594909668}}, '1284-1180-0009': {'whisper_pgd_200': {'stoi': 0.9995206509882318, 'waveformCompare': 0.5655733346939087, 'textCompare': 0.5846201181411743}}, '7729-102255-0013': {'whisper_pgd_200': {'stoi': 0.9992247351067641, 'waveformCompare': 0.5904216766357422, 'textCompare': 0.6044089794158936}}, '7021-79740-0000': {'whisper_pgd_200': {'stoi': 0.9976408367088178, 'waveformCompare': 0.6572021842002869, 'textCompare': 0.5992988348007202}}, '61-70968-0010': {'whisper_pgd_200': {'stoi': 0.9993100562980369, 'waveformCompare': 0.6498174071311951, 'textCompare': 1.4485182762145996}}, '908-31957-0009': {'whisper_pgd_200': {'stoi': 0.9990751411937342, 'waveformCompare': 0.5628390908241272, 'textCompare': 0.38898777961730957}}, '6829-68771-0006': {'whisper_pgd_200': {'stoi': 0.9997151834653525, 'waveformCompare': 0.5311934947967529, 'textCompare': 0.38266420364379883}}, '6930-81414-0019': {'whisper_pgd_200': {'stoi': 0.9999026246175702, 'waveformCompare': 0.5739794969558716, 'textCompare': 2.2958714962005615}}, '121-127105-0023': {'whisper_pgd_200': {'stoi': 0.9998398392023814, 'waveformCompare': 0.5672634840011597, 'textCompare': 0.31450581550598145}}, '5683-32866-0005': {'whisper_pgd_200': {'stoi': 0.999297906998457, 'waveformCompare': 0.8083340525627136, 'textCompare': 1.4637527465820312}}, '4446-2275-0020': {'whisper_pgd_200': {'stoi': 0.9998780344424311, 'waveformCompare': 0.45605695247650146, 'textCompare': 0.5714812278747559}}, '237-126133-0016': {'whisper_pgd_200': {'stoi': 0.9996355286792318, 'waveformCompare': 0.8607471585273743, 'textCompare': 2.6255576610565186}}, '1580-141083-0049': {'whisper_pgd_200': {'stoi': 0.9998635175746766, 'waveformCompare': 0.69160395860672, 'textCompare': 0.6531670093536377}}, '1284-1181-0013': {'whisper_pgd_200': {'stoi': 0.9993261229816737, 'waveformCompare': 0.6003170609474182, 'textCompare': 0.44843316078186035}}, '2961-961-0003': {'whisper_pgd_200': {'stoi': 0.9993598619739334, 'waveformCompare': 0.6251153945922852, 'textCompare': 0.4036521911621094}}, '237-134500-0019': {'whisper_pgd_200': {'stoi': 0.9994569887398671, 'waveformCompare': 0.5802738666534424, 'textCompare': 0.6459579467773438}}, '1320-122617-0000': {'whisper_pgd_200': {'stoi': 0.998952601339594, 'waveformCompare': 0.5879034996032715, 'textCompare': -0.034444570541381836}}, '2830-3980-0022': {'whisper_pgd_200': {'stoi': 0.997244427686058, 'waveformCompare': 0.6562025547027588, 'textCompare': -0.4829568862915039}}, '8463-294828-0008': {'whisper_pgd_200': {'stoi': 0.9996040802032269, 'waveformCompare': 0.5832113027572632, 'textCompare': 2.112032413482666}}, '6829-68769-0042': {'whisper_pgd_200': {'stoi': 0.9992053756793725, 'waveformCompare': 0.43334951996803284, 'textCompare': -0.07732534408569336}}, '5639-40744-0013': {'whisper_pgd_200': {'stoi': 0.9995298777791839, 'waveformCompare': 0.5798649191856384, 'textCompare': 0.03738880157470703}}, '61-70968-0048': {'whisper_pgd_200': {'stoi': 0.999391050088793, 'waveformCompare': 0.6688273549079895, 'textCompare': 0.9778945446014404}}, '121-127105-0002': {'whisper_pgd_200': {'stoi': 0.9998030034753945, 'waveformCompare': 0.634856641292572, 'textCompare': 0.591354489326477}}, '908-157963-0021': {'whisper_pgd_200': {'stoi': 0.9980412780093779, 'waveformCompare': 0.5752676725387573, 'textCompare': 1.0392125844955444}}, '5105-28240-0008': {'whisper_pgd_200': {'stoi': 0.9995486239514656, 'waveformCompare': 0.4930609464645386, 'textCompare': 0.29528725147247314}}, '1320-122612-0013': {'whisper_pgd_200': {'stoi': 0.998658752967975, 'waveformCompare': 0.6113629341125488, 'textCompare': 0.140097975730896}}, '2830-3980-0070': {'whisper_pgd_200': {'stoi': 0.9923516163383445, 'waveformCompare': 0.6694192886352539, 'textCompare': 1.6327998638153076}}, '7021-85628-0023': {'whisper_pgd_200': {'stoi': 0.9993155279528171, 'waveformCompare': 0.6049789190292358, 'textCompare': 0.3593258857727051}}, '2830-3980-0066': {'whisper_pgd_200': {'stoi': 0.9984737159532246, 'waveformCompare': 0.7338721752166748, 'textCompare': 1.256879210472107}}, '61-70970-0007': {'whisper_pgd_200': {'stoi': 0.9991019269259175, 'waveformCompare': 0.6702274680137634, 'textCompare': 0.7547496557235718}}, '8555-284447-0013': {'whisper_pgd_200': {'stoi': 0.9991037114600235, 'waveformCompare': 0.6992753148078918, 'textCompare': 0.20041930675506592}}, '1580-141083-0022': {'whisper_pgd_200': {'stoi': 0.9998352239579862, 'waveformCompare': 0.6341947913169861, 'textCompare': 0.8000936508178711}}, '7021-85628-0013': {'whisper_pgd_200': {'stoi': 0.9990102708204844, 'waveformCompare': 0.5987324118614197, 'textCompare': 2.731715440750122}}, '672-122797-0040': {'whisper_pgd_200': {'stoi': 0.9970099742380805, 'waveformCompare': 0.6545708775520325, 'textCompare': 0.5017192363739014}}, '2961-961-0020': {'whisper_pgd_200': {'stoi': 0.9996177856872908, 'waveformCompare': 0.6761829853057861, 'textCompare': 0.5833213329315186}}, '2830-3979-0009': {'whisper_pgd_200': {'stoi': 0.9975426151561322, 'waveformCompare': 0.5995177030563354, 'textCompare': 0.3237183094024658}}, '4970-29093-0001': {'whisper_pgd_200': {'stoi': 0.9997126453903299, 'waveformCompare': 0.5252920389175415, 'textCompare': 0.8242392539978027}}, '237-134500-0025': {'whisper_pgd_200': {'stoi': 0.9998006127403106, 'waveformCompare': 0.7784619331359863, 'textCompare': 1.3057317733764648}}, '8555-284447-0011': {'whisper_pgd_200': {'stoi': 0.9984180945539037, 'waveformCompare': 0.6141804456710815, 'textCompare': 0.43703699111938477}}, '8230-279154-0027': {'whisper_pgd_200': {'stoi': 0.9992475709435461, 'waveformCompare': 0.5977399945259094, 'textCompare': 0.14628994464874268}}, '4446-2275-0022': {'whisper_pgd_200': {'stoi': 0.9978542888954651, 'waveformCompare': 0.6730592250823975, 'textCompare': 0.2243649959564209}}, '5142-33396-0003': {'whisper_pgd_200': {'stoi': 0.999421759424851, 'waveformCompare': 0.6420658230781555, 'textCompare': 0.6193153858184814}}, '4446-2273-0011': {'whisper_pgd_200': {'stoi': 0.9998473457926376, 'waveformCompare': 0.5905027389526367, 'textCompare': -0.10492444038391113}}, '1221-135766-0003': {'whisper_pgd_200': {'stoi': 0.9987988134047883, 'waveformCompare': 0.7786449790000916, 'textCompare': 0.8971132040023804}}, '4446-2271-0010': {'whisper_pgd_200': {'stoi': 0.998696733611694, 'waveformCompare': 0.6314092874526978, 'textCompare': 0.5463848114013672}}, '4970-29095-0026': {'whisper_pgd_200': {'stoi': 0.9995923138442828, 'waveformCompare': 0.6982489228248596, 'textCompare': 1.5370019674301147}}, '8455-210777-0062': {'whisper_pgd_200': {'stoi': 0.9985692594070907, 'waveformCompare': 0.5525128245353699, 'textCompare': 1.7994303703308105}}, '4507-16021-0053': {'whisper_pgd_200': {'stoi': 0.9962008008731563, 'waveformCompare': 0.5935839414596558, 'textCompare': 1.0304594039916992}}, '6930-75918-0000': {'whisper_pgd_200': {'stoi': 0.9985801588814888, 'waveformCompare': 0.5601746439933777, 'textCompare': 0.5128655433654785}}, '6930-76324-0001': {'whisper_pgd_200': {'stoi': 0.9995551746993355, 'waveformCompare': 0.8184854984283447, 'textCompare': 2.1107089519500732}}, '237-134500-0042': {'whisper_pgd_200': {'stoi': 0.9995885047371096, 'waveformCompare': 0.5546920895576477, 'textCompare': 1.1184115409851074}}, '2961-961-0007': {'whisper_pgd_200': {'stoi': 0.999464851726688, 'waveformCompare': 0.5594338774681091, 'textCompare': 0.409328818321228}}, '4446-2275-0012': {'whisper_pgd_200': {'stoi': 0.9980754612207564, 'waveformCompare': 0.6889488101005554, 'textCompare': 1.013907790184021}}, '4507-16021-0046': {'whisper_pgd_200': {'stoi': 0.9992998481171613, 'waveformCompare': 0.6088026165962219, 'textCompare': 1.2790510654449463}}, '5105-28240-0019': {'whisper_pgd_200': {'stoi': 0.996970792636088, 'waveformCompare': 0.5558785796165466, 'textCompare': 0.6120316982269287}}, '1580-141083-0048': {'whisper_pgd_200': {'stoi': 0.9998057352168883, 'waveformCompare': 0.6992724537849426, 'textCompare': 1.9495124816894531}}, '8555-284449-0001': {'whisper_pgd_200': {'stoi': 0.9992558795797887, 'waveformCompare': 0.6971713900566101, 'textCompare': 0.23553717136383057}}, '61-70970-0035': {'whisper_pgd_200': {'stoi': 0.9988837712963505, 'waveformCompare': 0.651553750038147, 'textCompare': 1.1741180419921875}}, '1995-1837-0008': {'whisper_pgd_200': {'stoi': 0.9993179755781385, 'waveformCompare': 0.5327089428901672, 'textCompare': 1.1653125286102295}}}\n"
     ]
    }
   ],
   "source": [
    "print(all_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = os.path.join(data_dir,'results.json')\n",
    "with open(outfile,\"w\") as f:\n",
    "    json.dump(all_res,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics Test Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_rate, samples = wavfile.read(\"/home/amank/mlsp-speech-noiser-2/og.wav\")\n",
    "# orig = np.float32(samples)\n",
    "# mel_spec = log_mel_spectrogram(orig) # what sampling rate is used?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fake_text = \"Chapter 16 I might have told you of the phenomenal beginning to the entire expedition but I wanted to you to see every step by which we came I too agree by what Margaret wished.\"\n",
    "# real_text = \"Chapter 16 I might have told you of the beginning of this liaison in a few lines but I wanted to you to see every step by which we came I too agree by what Margaret wished.\"\n",
    "# real_loss = getProb(mel_spec.to(model.device), real_text)\n",
    "# fake_loss = getProb(mel_spec.to(model.device), fake_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# real_loss, fake_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DF Test Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def getPreProcessedInput(voice_sample_path):\n",
    "#     in_fpath = Path(voice_sample_path.replace(\"\\\"\", \"\").replace(\"\\'\", \"\"))\n",
    "#     preprocessed_wav, sr = encoder.preprocess_wav(in_fpath,normalize=False)\n",
    "#     toReturn = torch.tensor(preprocessed_wav,requires_grad=True)\n",
    "#     return (toReturn, sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sample_rate, samples = wavfile.read(\"/home/amank/mlsp-speech-noiser-2/og.wav\")\n",
    "# cleaned, sr = getPreProcessedInput(\"/home/amank/mlsp-speech-noiser-2/og.wav\")\n",
    "# real_text = \"Chapter 16 I might have told you of the beginning of this liaison in a few lines but I wanted to you to see every step by which we came I too agree by what Margaret wished.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spec = AudioSynthesisRun(cleaned,\"My favorite color is blue and my country of origin is the United States of America.\")\n",
    "# generated_wav = vocoder.infer_waveform(spec)\n",
    "# generated_wav = nn.functional.pad(generated_wav, (0, synthesizer.sample_rate), mode=\"constant\")\n",
    "# generated_speech = np.array(generated_wav.clone().detach())\n",
    "# wavfile.write('test.wav', synthesizer.sample_rate, generated_speech)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
